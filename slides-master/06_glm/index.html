<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Data Science for Linguists</title>
    <meta charset="utf-8" />
    <meta name="author" content="Joseph V. Casillas, PhD" />
    <script src="assets/header-attrs/header-attrs.js"></script>
    <link href="assets/remark-css/hygge.css" rel="stylesheet" />
    <link href="assets/remark-css/rutgers.css" rel="stylesheet" />
    <link href="assets/remark-css/rutgers-fonts.css" rel="stylesheet" />
    <link href="assets/tile-view/tile-view.css" rel="stylesheet" />
    <script src="assets/tile-view/tile-view.js"></script>
    <link href="assets/panelset/panelset.css" rel="stylesheet" />
    <script src="assets/panelset/panelset.js"></script>
    <script type="application/json" id="xaringanExtra-editable-docid">{"id":"x3ab6d2ee7cd42ca9f44d536aa9a3c68","expires":14}</script>
    <script src="assets/himalaya/himalaya.js"></script>
    <script src="assets/js-cookie/js.cookie.js"></script>
    <link href="assets/editable/editable.css" rel="stylesheet" />
    <script src="assets/editable/editable.js"></script>
    <script src="assets/kePrint/kePrint.js"></script>
    <link href="assets/lightable/lightable.css" rel="stylesheet" />
    <script src="https://use.fontawesome.com/5235085b15.js"></script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Data Science for Linguists
]
.subtitle[
## The Generalized Linear Model
]
.author[
### Joseph V. Casillas, PhD
]
.date[
### Rutgers University</br>Spring 2023</br>Last update: 2023-04-12
]

---













class: title-slide-section-grey, middle

# Review

---
background-image: url(./assets/img/01_distributions.png)
background-size: contain

--

background-image: url(./assets/img/02_clt.png)
background-size: contain

--

background-image: url(./assets/img/03a_nhst.png)
background-size: contain

--

background-image: url(./assets/img/03b_hypothesis_testing.png)
background-size: contain

--

background-image: url(./assets/img/03c_ttest.png)
background-size: contain

--

background-image: url(./assets/img/05_correlation.png)
background-size: 400px

--

background-image: url(./assets/img/06a_bvar_reg.png)
background-size: contain

--

background-image: url(./assets/img/06b_bvar_reg.png)
background-size: contain

--

background-image: url(./assets/img/07_general_lm01.png)
background-size: contain

---
background-image: url(./assets/img/01_distributions.png), url(./assets/img/03a_nhst.png), url(./assets/img/05_correlation.png), url(./assets/img/06b_bvar_reg.png), url(./assets/img/07_general_lm01.png)
background-size: 400px, 400px, 400px, 400px, 400px
background-position: 5% 10%, 50% 50%, 95% 10%, 0% 95%, 100% 95%

---

# Review

.pull-left[

### What we know, where we've been

.large[
- Distributions
  - Normal distribution
  - CLT
- Hypothesis testing
  - z-tests
  - t-tests
- Bivariate correlation
- The linear model
  - Bivariate regression
  - Multiple regression and correlation
- The general linear model
  - Continuous predictors
  - Categorical predictors
]
]

--

.pull-right[

### What they have in common

.large[
- Criterion
  - Continuous
  - Linear relationship with predictors
  - `\(-\infty\)` : `\(\infty\)`
  - Errors are normally distributed
]
]

---

# (P)review

### Where we're headed

.large[
- Sometimes we measure phenomena that are not continuous variables ranging from 
  `\(-\infty\)` : `\(\infty\)`
]

&lt;p&gt;&lt;/p&gt;

.large[
- For example, we often analyze binary outcomes
  - Decisions
  - The presence/absence of a linguistic feature
  - Categorical perception 
]

&lt;p&gt;&lt;/p&gt;

.large[
- Sometimes we count things
  - Number of languages in a given area
  - Number of code switches during a linguistic interview
]

&lt;p&gt;&lt;/p&gt;

.large[
- We can extend our model in order to account for these different types of 
*dependent* variables
]

---
class: title-slide-section-grey, middle

# The generalized linear model

---

# The generalized linear model

### History

- Formulated by Nelder and Wedderburn (1972)
- The purpose was to unify (again) the different models being used at the time

### How

Recall that linear models contain a *systematic component* that specifies 
predictors (*X*&lt;sub&gt;1&lt;/sub&gt;, *X*&lt;sub&gt;2&lt;/sub&gt; ... *X*&lt;sub&gt;*k*&lt;/sub&gt;), which, 
in turn, create our linear predictor (Œ≤&lt;sub&gt;0&lt;/sub&gt; + Œ≤&lt;sub&gt;1&lt;/sub&gt;*x*&lt;sub&gt;1&lt;/sub&gt; ... Œ≤&lt;sub&gt;k&lt;/sub&gt;*x*&lt;sub&gt;k&lt;/sub&gt;). At a minimum, a GLM contains the following: 

.pull-left[

1) .blue[A data *distribution*]. This refers to the probability distribution of 
the response variable.

2) .blue[A *linking function*] that transforms the criterion used to model the 
data. It *links* the data distribution of the response variable to the 
systematic component of the model.

]

--

.pull-right[

3) .blue[An *estimator*], or method for obtaining parameter estimates

You (the researcher) are responsible for selecting (1) and (2). (3) is always 
the same.

]

---
background-image: url(./assets/img/glm_distributions.png)
background-size: 600px
background-position: 95% 50%

# The generalized linear model

### Distributions

#### .Large[Meet the (exponential) family]

.Large[
The exponential family is a series&lt;br&gt;of probability distributions, each&lt;br&gt;with its own properties. 

There are ¬±12, but we'll focus on 3:

- Gaussian 
- Binomial 
- Poisson 
]

---

# The generalized linear model

### Linking functions

.Large[
The linking function transforms the response variable in the manner most 
appropriate given the data distribution you have selected. 

- .RUred[Identity]: for gaussian response variable (normal distribution)

- .blue[Logit]: for binary response variable (binomial distribution)

- .green[Log]: for count response variable (poisson distribution)

]

--

(more detail later)

---

# The generalized linear model

### The estimator: Maximum Likelihood Estimation (MLE)

&lt;ru-blockquote&gt;
Maximum likelihood estimation is the method that determines the values of the
parameters of the model. The parameter estimates are obtained in a way that 
maximizes the likelihood that the process described by the model produced 
the data that were actually observed.&lt;sup&gt;1&lt;/sup&gt;
&lt;/ru-blockquote&gt;

&lt;img src="index_files/figure-html/mle-ex-1.png" width="75%" style="display: block; margin: auto;" /&gt;

.footnote[&lt;sup&gt;1&lt;/sup&gt; [Brooks-Bartlett](https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1) (2018)]

---
background-image: url(./assets/img/06a_bvar_reg.png)
background-size: 600px
background-position: 98%
class: middle

.pull-left[

## Recall that classical linear regression uses .RUred[*ordinary least squares estimation*] to determine the line that minimizes the residual sum of squares.

]

--

.footnote[You don't need to know the details behind MLE,  
but it never hurts to understand what is going on  
under the hood. [Brooks-Bartlett](https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1) (2018)  
is a good place to start if you are interested.]

---
count: false

# The generalized linear model

.pull-left[

### Something old

- It turns out we've spent the previous 11 weeks working with the gaussian 
distribution
- Gaussian is another way of saying normal
- This means we can think of standard linear regression in the general linear model as a special case of the generalized linear model
  - The errors are normally (gaussian) distributed
  - The criterion is associated with the linear predictors via an identity 
  linking function 
  - Instead of least squares estimation we use maximum likelihood estimation

]

--

.pull-right[

### Something new

.Large["y as a function of x"]

]

---
count: false

# The generalized linear model

.pull-left[

### Something old

- It turns out we've spent the previous 11 weeks working with the gaussian 
distribution
- Gaussian is another way of saying normal
- This means we can think of standard linear regression in the general linear model as a special case of the generalized linear model
  - The errors are normally (gaussian) distributed
  - The criterion is associated with the linear predictors via an identity 
  linking function 
  - Instead of least squares estimation we use maximum likelihood estimation

]

.pull-right[

### Something new

.Large["y as a function of x"]

.Large[y ~ x]

]

---
count: false

# The generalized linear model

.pull-left[

### Something old

- It turns out we've spent the previous 11 weeks working with the gaussian 
distribution
- Gaussian is another way of saying normal
- This means we can think of standard linear regression in the general linear model as a special case of the generalized linear model
  - The errors are normally (gaussian) distributed
  - The criterion is associated with the linear predictors via an identity 
  linking function 
  - Instead of least squares estimation we use maximum likelihood estimation

]

.pull-right[

### Something new

.Large[

"y as a function of x"

y ~ x

|          |        |                                           |
| :------- | :----: | :---------------------------------------- |
| `\(y_{i}\)`  | `\(\sim\)` | `\(Normal(\mu_{i}, \sigma)\)`                 |
| `\(u_{i}\)`  | `\(=\)`    | `\(\alpha + \beta_{1} \times predictor_{i}\)` |
| `\(\sigma\)` | `\(\sim\)` | `\(Normal(0, \sigma^2)\)`                     |

]
]

---

# The generalized linear model

.pull-left[

### Something old

- It turns out we've spent the previous 11 weeks working with the gaussian 
distribution
- Gaussian is another way of saying normal
- This means we can think of standard linear regression in the general linear model as a special case of the generalized linear model
  - The errors are normally (gaussian) distributed
  - The criterion is associated with the linear predictors via an identity 
  linking function 
  - Instead of least squares estimation we use maximum likelihood estimation

]

.pull-right[

### Something new

- We can use different combinations of distributions and linking functions to 
model different outcome variables
- There are many options. Learning new modeling tools will open your mind to 
new experimental possibilities (if you only have a hammer, everything is a nail)
- We will focus on two types of regression that can be fit in the Generalized 
Linear Model framework: 
  1. Logistic regression (outcome variable is binary)
  2. Poisson regression (outcome variable represents counts)

]

---

# The generalized linear model

### Assumptions

.Large[
- Data are independently distributed (independence of scores)

- Dependent variable follows a distribution from the exponential family

- Linear relationship between transformed response variable and predictors 
(linear relationship is result of linking function)

- Errors are independent (NOTE: they do not have to be normally distributed)
]

---

# The generalized linear model

### Doing it in R

.Large[

#### The `glm()` function

- Thus far we have used the `lm()` function to fit models

- The `glm()` function works in the same way

]

--


```r
my_glm &lt;- glm(
  criterion ~ pred1 + pred2 + pred1:pred2, # model formula
  data = my_df,                            # select dataframe
* family = gaussian(link = "identity")
)
```

--

- Steps
  1. Specify the .blue[model formula]: `criterion ~ pred1 + pred2 + pred1:pred2`
  2. Select the .red[dataframe]: `data = my_df`
  3. Select a .green[distribution family] and .green[linking function]: 
  `family = gaussian(link = "identity")`

---

# The generalized linear model

.pull-left[


```r
# Standard lm()
lm(
  formula = mpg ~ drat, 
  data = mtcars
  # No likelihood/linking function
)
```

&lt;table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -7.525 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.477 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.374 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.18 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; drat &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.678 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.507 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.096 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.00 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

.pull-right[


```r
# glm() equivalent
glm(
  formula = mpg ~ drat, 
  data = mtcars, 
* family = gaussian(link = "identity")
)
```

&lt;table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -7.525 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.477 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.374 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.18 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; drat &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.678 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.507 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.096 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.00 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

--

&lt;/br&gt;

&lt;div align="center"&gt;
&lt;img width="400" src="./assets/img/russian_dolls.png"&gt;
&lt;/div&gt;

.center[**The standard linear model is a special case of the GLM**]

---
















background-color: black
class: middle

&lt;img src="index_files/figure-html/log-reg-plot-1.png" width="60%" style='float:right' /&gt;

# Logistic regression

---

# Logistic regression

.Large[
### Model setup

.pull-left[
.center[y ~ x]

- The criterion is binary (0/1)

- The distribution for binary data is either the **bernoulli** or **binomial** distribution

- The linking function is the **logit**
]
]

--

.pull-right[

&lt;br&gt;

.Large[
|                |        |                           |
| -------------: | :----- | :------------------------ |
| `\(y_{i}\)`        | `\(\sim\)` | `\(Bernoulli(1, p_{i})\)`     |
| `\(logit(p)_{i}\)` | `\(=\)`    | `\(\alpha + \beta_{1}x_{i}\)` |
]
]

---

# Logistic regression

### How it works

.pull-left[
.Large[
- The logit linking function transforms the criterion so it can be modeled by the linear predictor

`$$logit(p) = log(\frac{p}{1 - p})$$`
]
]

--

.pull-right[
.Large[
- In other words, the linking function transforms the dichotomous 0/1 outcomes to `\(-\infty\)` : `\(\infty\)`

`$$log(\frac{p_{i}}{1 - p_{i}}) = \alpha + \beta_{1}X_{1}$$`
]
]

---
layout: false
class: middle

<blockquote class="tiktok-embed" cite="https://www.tiktok.com/@chelseaparlettpelleriti/video/6871246394531876102" data-video-id="6871246394531876102" data-embed-from="oembed" style="max-width: 605px;min-width: 325px;" > <section> <a target="_blank" title="@chelseaparlettpelleriti" href="https://www.tiktok.com/@chelseaparlettpelleriti?refer=embed">@chelseaparlettpelleriti</a> <p>üêßüßä and that's on making sure you create a safe place to ask questions as a teacher üòé‚úåüèº <a title="statstiktok" target="_blank" href="https://www.tiktok.com/tag/statstiktok?refer=embed">#statsTikTok</a> <a title="datascience" target="_blank" href="https://www.tiktok.com/tag/datascience?refer=embed">#datascience</a></p> <a target="_blank" title="‚ô¨ The Wonder Pets! - Wonder Pets" href="https://www.tiktok.com/music/The-Wonder-Pets-6841272099479227142?refer=embed">‚ô¨ The Wonder Pets! - Wonder Pets</a> </section> </blockquote> 
<!--SHINY.SINGLETON[e123f97525dee37cc53ba5b9f17fd3caf1b72842]-->
<script async data-external="1" src="https://www.tiktok.com/embed.js"></script>
<style>blockquote.tiktok-embed {border:unset;padding:unset;}</style>
<!--/SHINY.SINGLETON[e123f97525dee37cc53ba5b9f17fd3caf1b72842]-->

---

&lt;img src="index_files/figure-html/lin-log-comp-1.png" width="100%" /&gt;

---

# Logistic regression

### What you need to know

.large[
- Logistic regression is the most appropriate way to model binary response 
variables (0/1)

- The model calculates the probability that y = 1, i.e., the probability of a 
"success", or presence of something

- Model output from logistic regression is similar to `lm()`

- Model interpretation "works" the same way, i.e., a 1-unit change in 
`predictor` is associated with a change of X in the criterion

- But... the parameter estimates represent changes in the log-odds of y = 1

- This is much less intuitive, much more difficult to understand without some 
math
]

---

# Logistic regression

### Example

.large[
- You are interested in understanding the perception of stop voicing in 
English bilabials 

- You conducted an experiment in which participants heard a range of 
bilabial stops that differed in voice-onset time

- The stimuli ranged from -60 ms to 60 ms in 10 ms increments 

- Participants were presented stimuli drawn at random from the continuum and 
identified the sounds as /b/'s or /p/'s

- A /p/ response is coded as a 1
]

---
background-image: url(./assets/img/vot.png)
background-size: contain

---

# Logistic regression

.left-column[

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

```r
mod_log &lt;- glm(
  resp ~ vot, 
  data = vot_logistic_data, 
  family = "binomial"
)
```

]

.right-column[


```

Call:
glm(formula = resp ~ vot, family = "binomial", data = vot_logistic_data)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.3085  -0.6583  -0.2198   0.6503   2.9320  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -0.84614    0.06089   -13.9   &lt;2e-16 ***
vot          0.05731    0.00213    26.9   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 3482.8  on 2599  degrees of freedom
Residual deviance: 2063.6  on 2598  degrees of freedom
AIC: 2067.6

Number of Fisher Scoring iterations: 5
```

]

---

# Logistic regression

### Example

.Large[
- We can convert the log-odds to probabilities by calculating the inverse 
logit&lt;sup&gt;1&lt;/sup&gt;
]


```r
inv_logit(mod_log) %&gt;% kable(., format = 'html')
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; variables &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; betas &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; prob &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.8461443 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.3002423 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; vot &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0573077 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.5143230 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--

.Large[
- This is still difficult to interpret... a plot might help. 
]

&lt;/br&gt;&lt;/br&gt;

&lt;sup&gt;1&lt;/sup&gt; Inverse logit = `\(\frac{1}{1 + exp(-x)}\)`

---
class: middle

&lt;img src="index_files/figure-html/vot-plot-1.png" width="100%" /&gt;

---
class: middle

.pull-left[

```r
inv_logit(mod_log) %&gt;% kable(., format = 'html')
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; variables &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; betas &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; prob &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.8461443 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.3002423 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; vot &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0573077 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.5143230 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;/br&gt;

- Now the intercept is interpretable  
(note it is already centered)

- What does the parameter estimate  
for VOT mean?

- Can calculate how the probability  
differs from one specific point to  
another?

]

.pull-right[

&lt;img src="index_files/figure-html/repeat-glm-vot-plot-1.png" width="100%" /&gt;

]

---
class: middle

.pull-left[

#### We can use the model coefficients

&lt;table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.846 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.061 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -13.897 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; vot &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.057 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.002 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 26.899 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

- Calculate the inverse logit of the  
linear equation:  

`$$\alpha + \beta_{VOT} * 10ms$$`


```r
plogis(-0.846 + 0.057 * 10)
```

```
## [1] 0.4314347
```

- What about the change in probability of selecting /p/ when shifting from 10 ms 
to 20 ms?


```r
plogis(-0.846 + 0.057 * 20) - 
plogis(-0.846 + 0.057 * 10)
```

```
## [1] 0.1415404
```

]

.pull-right[

&lt;img src="index_files/figure-html/repeat-glm-vot-plot2-1.png" width="100%" /&gt;

The shift from 10ms to 20 ms VOT corresponds  
with a positive difference of 14% in 
the probability of selecting /p/

]

---

# Logistic regression

### Summary

.large[
- Logistic regression is a powerful tool for modeling binary data

- The `glm()` function works similarly to the `lm()` function 

- We test for main effects and interactions the same way too, i.e., using 
nested model comparisons with the `anova()` function

- The exponential family and corresponding linking function are  
`family = binomial(link = "logit")`

- Interpretation of logistic regression works the same way as classic linear 
regression 

- Parameter estimates are evaluated in log odds (and require some work in order 
to accurately interpret them)
]

---
layout: false
class: middle

<blockquote class="tiktok-embed" cite="https://www.tiktok.com/@chelseaparlettpelleriti/video/6828303282482449669" data-video-id="6828303282482449669" data-embed-from="oembed" style="max-width: 605px;min-width: 325px;" > <section> <a target="_blank" title="@chelseaparlettpelleriti" href="https://www.tiktok.com/@chelseaparlettpelleriti?refer=embed">@chelseaparlettpelleriti</a> <p>üôÉüòâ <a title="statstiktok" target="_blank" href="https://www.tiktok.com/tag/statstiktok?refer=embed">#statsTiktok</a> <a title="machinelearning" target="_blank" href="https://www.tiktok.com/tag/machinelearning?refer=embed">#machineLearning</a></p> <a target="_blank" title="‚ô¨ original sound - Cass Martin " href="https://www.tiktok.com/music/original-sound-6622403695122320133?refer=embed">‚ô¨ original sound - Cass Martin </a> </section> </blockquote> 
<!--SHINY.SINGLETON[e123f97525dee37cc53ba5b9f17fd3caf1b72842]-->
<script async data-external="1" src="https://www.tiktok.com/embed.js"></script>
<style>blockquote.tiktok-embed {border:unset;padding:unset;}</style>
<!--/SHINY.SINGLETON[e123f97525dee37cc53ba5b9f17fd3caf1b72842]-->

---

# Practice

- [Logistic regression practice](./assets/logistic_regression_walkthrough/glm_logistic.zip)

---






















background-color: black
class: middle

&lt;img src="index_files/figure-html/poisson-plot-1.png" width="60%" style='float:right' /&gt;

# Poisson regression

---

# Poisson regression

.pull-left[

### Model setup

- The criterion is a non-negative number (0, 1, 2...)

- The distribution for count data is typically the **poisson** distribution

- The linking function is **log** 

### How it works

- The log linking function transforms the criterion so that it can be modeled by 
the linear predictor

]

.pull-right[

&lt;br&gt;&lt;br&gt;&lt;br&gt;

.Large[
|                    |        |                           |
| -----------------: | :----- | :------------------------ |
| `\(y_{i}\)`            | `\(\sim\)` | `\(Poisson(\lambda_{i})\)`     |
| `\(log(\lambda)_{i}\)` | `\(=\)`    | `\(\alpha + \beta_{1}x_{i}\)` |
]

]

---
class: middle

&lt;img src="index_files/figure-html/lin-poisson-comp-1.png" width="100%" /&gt;

---

# Poisson regression

### What you need to know

.large[
- Poisson regression is the most appropriate way to model count data 
(0, 1, 2...)

- Model output from poisson regression is similar to `lm()`

- Model interpretation "works" the same way, i.e., a 1-unit change in 
`predictor` is associated with a change of X in the criterion

- But... the parameter estimates represent changes in the criterion on a 
logarithmic scale

- The parameter estimates that can be interpreted as multiplicative effects

- This is not too difficult to understand
]

---

# Poisson regression

### Example

.pull-left[


```r
glm(
  units ~ temp, 
  data = ice_cream_poisson_data, 
* family = poisson(link = "log")
) 
```

&lt;table class="table" style="font-size: 14px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.496 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.015 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 165.709 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; temp &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.039 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 225.702 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

--

.pull-right[

&lt;img src="index_files/figure-html/icecream-plot1-1.png" width="100%" /&gt;

]

--

.footnote[
- A 1 unit change in temperature is associated with a  
change of 0.04 log units in ice cream sold. 

- We can exponentiate 0.04 to make it more  
interpretable.  `exp(coef(mod_poisson)[2])` = 
1.0400058

- A 1 unit change in temperature gives a 4% positive  
increase in ice cream sold.
]

---

# Poisson regression

### Example

.pull-left[


```r
glm(
* units ~ temp + city,
  data = ice_cream_poisson_data, 
  family = poisson(link = "log")
)
```

&lt;table class="table" style="font-size: 14px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.457 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.016 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 157.027 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; temp &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.043 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 229.264 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; cityTucson &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.514 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.007 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -78.088 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

--

.pull-right[

&lt;img src="index_files/figure-html/icecream-plot2-1.png" width="100%" /&gt;

]

--

.footnote[
- A 1 unit change in temperature is associated with a  
positive difference of approx. 4% in ice cream sold  
in NYC. 

- When temp = 0, ice cream sold in Tucson is approx.  
42% less

]

---

# Poisson regression

### Example

.pull-left[


```r
ice_cream_poisson_data %&gt;% 
  mutate(temp_c = temp - mean(temp)) %&gt;% 
* glm(units ~ temp_c + city,
      data = ., 
      family = poisson(link = "log"))
```

&lt;table class="table" style="font-size: 14px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.387 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.005 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1113.731 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; temp_c &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.043 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 229.264 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; cityTucson &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.514 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.007 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -78.088 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

--

.pull-right[

&lt;img src="index_files/figure-html/icecream-plot3-1.png" width="100%" /&gt;

]

--

.footnote[
- A 1 unit change in temperature is associated with a  
positive difference of approx. 4% in ice cream sold  
in NYC. 

- At the average temperature (68.5), ice cream  
sold in Tucson is (still) approx. 42% less

]

---

# Poisson regression

### Summary

.large[
- Poisson regression is a powerful tool for modeling count data

- The `glm()` function works similarly to the `lm()` function 

- We test for main effects and interactions the same way too, i.e., using 
nested model comparisons with the `anova()` function

- The exponential family and corresponding linking function are  
`family = poisson(link = "log")`

- Interpretation of poisson regression works the same way as classic linear 
regression 

- Parameter estimates are evaluated on a log (multiplicative) scale and are 
not difficult to interpret
]

---

&lt;iframe src="https://jvcasillas.shinyapps.io/shiny_glm/" style="border:none;" height="800" width="100%"&gt;&lt;/iframe&gt;

---

# Practice

- [Poisson regression practice](./assets/poisson_regression_walkthrough/glm_poisson.zip)









---
exclude: true

(Wickham and Grolemund, 2016; Hardy, 1993b; Hardy, 1993c; Hardy, 1993d)

---
layout: false
class: title-slide-final, left

# References

[1] M. Hardy. "Assessing Group Differences in Effects". In: _Regression
with Dummy Variables_. Ed. by M. Hardy. Sage University Paper Series on
Quantitative Applications in the Social Sciences - 93. Newbury Park,
CA: Sage, 1993, pp. 29-63. ISBN: 9780803951280.

[2] M. Hardy. "Creating Dummy Variables". In: _Regression with Dummy
Variables_. Ed. by M. Hardy. Sage University Paper Series on
Quantitative Applications in the Social Sciences - 93. Newbury Park,
CA: Sage, 1993, pp. 7-17. ISBN: 9780803951280.

[3] M. Hardy. "Using Dummy Variables as Regressors". In: _Regression
with Dummy Variables_. Ed. by M. Hardy. Sage University Paper Series on
Quantitative Applications in the Social Sciences - 93. Newbury Park,
CA: Sage, 1993, pp. 18-28. ISBN: 9780803951280.

[4] H. Wickham and G. Grolemund. _R for Data Science: Import, Tidy,
Transform, Visualize, and Model Data_. O'Reilly Media, 2016.

Nelder, J., Wedderburn, R. (1972). Generalized Linear Models. *Journal of the Royal Statistical Society*. 135 (3). 370‚Äì384.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://www.jvcasillas.com/ru_xaringan/js/ru_xaringan.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "default",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
